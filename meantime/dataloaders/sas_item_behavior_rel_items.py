from os import replace
from .base import AbstractDataloader
from .bert import BertTrainDataset, BertEvalDataset
import pdb
import torch
import numpy as np


class SasDataloader(AbstractDataloader):
    def __init__(self, args, dataset):
        super().__init__(args, dataset)
        if args.dataloader_output_timestamp:
            self.sas_timestamps = self.calculate_sas_timestamps()
        else:
            self.sas_timestamps = None

    
    def calculate_sas_timestamps(self):
        sas_timestamps = {}  # user -> timestamps
        for user, dic in self.user2dict.items():
            times = dic['timestamps']
            try:
                time_scale = min(y - x for x, y in zip(times[:-1], times[1:]) if x != y)
            except:
                time_scale = 1
            min_time = min(times)
            sas_timestamps[user] = [round((t-min_time)/time_scale) + 1 for t in times]  # followed authors' original implementation
        return sas_timestamps

    @classmethod
    def code(cls):
        return 'sas_behavior_rel'

    def _get_dataset(self, mode):
        if mode == 'train':
            return self._get_train_dataset()
        elif mode == 'val':
            return self._get_eval_dataset('val')
        else:
            return self._get_eval_dataset('test')

    def _get_train_dataset(self):
        train_ranges = self.train_targets
        # pdb.set_trace()
        dataset = SasTrainDataset(self.args, self.dataset, self.train_negative_samples, self.rng, train_ranges, self.sas_timestamps)
        return dataset

    def _get_eval_dataset(self, mode):
        positions = self.validation_targets if mode=='val' else self.test_targets
        dataset = SasEvalDataset(self.args, self.dataset, self.test_negative_samples, positions, self.sas_timestamps)
        return dataset

class SasTrainDataset(BertTrainDataset):
    def __init__(self, args, dataset, negative_samples, rng, train_ranges, sas_timestamps):
        super().__init__(args, dataset, negative_samples, rng, train_ranges)
        self.args = args
        self.timestamps = sas_timestamps
        self.marank_mode = args.model_code in ['marank']
        self.marank_max_len = args.marank_max_len  # actual max_len if marank_mode=True
        self.output_user = args.dataloader_output_user
        self.item_count = len(dataset['smap'])
        self.item2id = dataset['smap']
        # pdb.set_trace()
        # self.attribute_count = len(dataset["attribute2id"])
        # self.id2item = dict([(value, key) for key, value in self.item2id.items()])
        # self.id2attri = dict([(value, key) for key, value in dataset["attribute2id"].items()])
        # self.item2cate = item2cate
        # self.cate2id = cate2id  11149:2098
        # self.item_id2cate_id = dict((self.item2id[key], self.cate2id[value]) for key, value in self.item2cate.items())
        # self.item_id2cate_id, self.item_id2brand_id, self.item_id2price_id = dataset['item_id2side_id_tripe'] #item_id to cate_id;
        self.item2relItemList = dataset['item2relItemList']
        # pdb.set_trace()
        if self.marank_mode:
            self.user2pos = {user:pos for user, pos in self.train_ranges}
    
    # #设置item_id转化为cate_id的映射字典;
    # def setItemId2CateId(self, item_id2cate_id):
    #     self.item_id2cate_id = item_id2cate_id
    
    def sample_negative_items(self, item_set, item_size):
        import random
        item = random.randint(1, item_size-1) 
        while item in item_set: 
            item = random.randint(1, item_size-1) 
        return item

    def sample_behavior_items(self, item_set, sample_num):
        import numpy as np
        if len(item_set)<= sample_num:
            return item_set
        else:
            return np.random.choice(item_set, sample_num, replace=False).tolist()

    def __getitem__(self, index):
        user, offset = self.index2user_and_offsets[index]
        if self.marank_mode:
            # sample offset randomly if marank_mode
            # original offset is generated by max_len,train_window (not marank_max_len) to ensure same amount of computation with other models
            pos = self.user2pos[user]
            offset = self.rng.randint(2, pos)  # offset is exclusive
        max_len = self.max_len if not self.marank_mode else self.marank_max_len
        seq = self.user2dict[user]['items']
        beg = max(0, offset-max_len-1)
        end = offset  # exclude offset (meant to be)
        seq = seq[beg:end]

        tokens = seq[:-1]
        padding_len = max_len - len(tokens)
        if self.marank_mode:
            labels = [seq[-1]]
            neg_samples = self.negative_samples[user]
            negative_labels = [self.rng.choice(neg_samples)]

            tokens = tokens + [tokens[-1]] * padding_len
        else:
            labels = seq[1:]
            neg_samples = self.negative_samples[user]  # a pool of negative items to choose from
            #随机负采样;
            # negative_labels = [self.sample_negative_items(seq, self.item_count) for _ in labels] #将valid item和test item选入到negative items;
            negative_labels = [self.rng.choice(neg_samples) for _ in labels]

            # sample behavior-based rel items
            sample_num = self.args.sample_num
            behavior_rel_items = []
            avg_rel_len_result = 0
            avg_rel_len_tmp = []
            for item_anchor in tokens:
                item_rels = []
                if item_anchor in self.item2relItemList:
                    # sample item
                    avg_rel_len_tmp.append(len(self.item2relItemList[item_anchor]))
                    item_rels = self.sample_behavior_items(self.item2relItemList[item_anchor], sample_num)
                else:
                    avg_rel_len_tmp.append(0)
                
                rel_item_padding_len = sample_num - len(item_rels)
                # pdb.set_trace()
                rel_items = [0] * rel_item_padding_len + item_rels
                behavior_rel_items.append(rel_items)
            
            # avg_rel_len_result = sum(avg_rel_len_tmp) *1.0 / len(tokens)
            # pdb.set_trace()
            behavior_rel_items = [[0 for _ in range(sample_num)] for _ in range(padding_len)] + behavior_rel_items
            # pdb.set_trace()
            tokens = [0] * padding_len + tokens
            labels = [0] * padding_len + labels
            negative_labels = [0] * padding_len + negative_labels

        
        # pdb.set_trace()
        # 数据增强
        d = {
            'tokens': torch.LongTensor(tokens),
            'labels': torch.LongTensor(labels),
            'negative_labels': torch.LongTensor(negative_labels),
            'behavior_rel_items': torch.LongTensor(behavior_rel_items),
        }
        if self.output_timestamps:
            timestamps = self.timestamps[user][beg:end-1]
            timestamps = [0] * padding_len + timestamps
            d['timestamps'] = torch.LongTensor(timestamps)
        if self.output_user:
            d['users'] = torch.LongTensor([user])
        return d


class SasEvalDataset(BertEvalDataset):
    def __init__(self, args, dataset, negative_samples, positions, sas_timestamps):
        super().__init__(args, dataset, negative_samples, positions)
        self.args = args
        self.timestamps = sas_timestamps
        self.output_user = args.dataloader_output_user
        self.marank_mode = args.model_code in ['marank']
        self.marank_max_len = args.marank_max_len
        item2id = dataset['smap']
        # self.attribute_count = len(dataset["attribute2id"])
        # self.item_id2cate_id = dict((item2id[key], cate2id[value]) for key, value in item2cate.items())
        # self.item_id2cate_id = item_id2cate_id
        # self.item_id2cate_id, self.item_id2brand_id, self.item_id2price_id = dataset['item_id2side_id_tripe'] #item_id to cate_id;
        self.item2relItemList = dataset['item2relItemList']
    def sample_behavior_items(self, item_set, sample_num):
        import numpy as np
        if len(item_set)<= sample_num:
            return item_set
        else:
            return np.random.choice(item_set, sample_num, replace=False).tolist()
    
    def __getitem__(self, index):
        user, pos = self.positions[index]
        seq = self.user2dict[user]['items']
        max_len = self.max_len if not self.marank_mode else self.marank_max_len
        beg = max(0, pos - max_len)
        # end = pos + 1
        # IMPORTANT:
        ## BERT => INLUCDE ANSWER ITEM AND MASK IT
        ## SAS => EXCLUDE ANSWER ITEM
        ## hence end = pos
        end = pos #valid_index: n-2, test_index: n-1
        answer = [seq[pos]]
        seq = seq[beg:end]

        negs = self.negative_samples[user]
        # answer = [seq[-1]]
        candidates = answer + negs
        labels = [1] * len(answer) + [0] * len(negs)

        # IMPORTANT : no [MASK]s for sas
        # so the next line is commented
        # seq[-1] = self.special_tokens.mask
        padding_len = max_len - len(seq)
        if self.marank_mode:
            seq = seq + [seq[-1]] * padding_len
        else:
            #添加cate_id作为side information;
            # cates = [self.item_id2cate_id[value] for value in seq]
            # cates = [0] * padding_len + cates
            # sample behavior-based rel items
            tokens = seq
            sample_num = self.args.sample_num
            behavior_rel_items = []
            avg_rel_len_result = 0
            avg_rel_len_tmp = []
            for item_anchor in tokens:
                item_rels = []
                if item_anchor in self.item2relItemList:
                    # sample item
                    avg_rel_len_tmp.append(len(self.item2relItemList[item_anchor]))
                    item_rels = self.sample_behavior_items(self.item2relItemList[item_anchor], sample_num)
                else:
                    avg_rel_len_tmp.append(0)
                
                rel_item_padding_len = sample_num - len(item_rels)
                # pdb.set_trace()
                rel_items = [0] * rel_item_padding_len + item_rels
                behavior_rel_items.append(rel_items)
            
            # avg_rel_len_result = sum(avg_rel_len_tmp) *1.0 / len(tokens)
            # behavior_rel_items = [[0 for _ in len(sample_num)] for _ in padding_len] + behavior_rel_items
            behavior_rel_items = [[0 for _ in range(sample_num)] for _ in range(padding_len)] + behavior_rel_items

            seq = [0] * padding_len + seq

        # candidate_cates = [self.item_id2cate_id[value] if value in self.item_id2cate_id else self.attribute_count for value in candidates]
        # candidate_brands = [self.item_id2brand_id[value] if value in self.item_id2brand_id else self.attribute_count + 1 for value in candidates]
        # candidate_prices = [self.item_id2price_id[value] if value in self.item_id2price_id else self.attribute_count + 2 for value in candidates]

        tokens = torch.LongTensor(seq)
        candidates = torch.LongTensor(candidates)
        labels = torch.LongTensor(labels)
        behavior_rel_items = torch.LongTensor(behavior_rel_items)

        d = {'tokens':tokens, 'candidates':candidates, 'labels':labels, 'behavior_rel_items': behavior_rel_items}
        if self.output_timestamps:
            timestamps = self.timestamps[user][beg:end]
            timestamps = [0] * padding_len + timestamps
            d['timestamps'] = torch.LongTensor(timestamps)
        if self.output_user:
            d['users'] = torch.LongTensor([user])
        return d