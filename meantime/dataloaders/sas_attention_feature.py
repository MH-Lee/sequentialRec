from .base import AbstractDataloader
from .bert import BertTrainDataset, BertEvalDataset
import pdb
import torch


class SasDataloader(AbstractDataloader):
    def __init__(self, args, dataset):
        super().__init__(args, dataset)
        if args.dataloader_output_timestamp:
            self.sas_timestamps = self.calculate_sas_timestamps()
        else:
            self.sas_timestamps = None

    
    def calculate_sas_timestamps(self):
        sas_timestamps = {}  # user -> timestamps
        for user, dic in self.user2dict.items():
            times = dic['timestamps']
            try:
                time_scale = min(y - x for x, y in zip(times[:-1], times[1:]) if x != y)
            except:
                time_scale = 1
            min_time = min(times)
            sas_timestamps[user] = [round((t-min_time)/time_scale) + 1 for t in times]  # followed authors' original implementation
        return sas_timestamps

    @classmethod
    def code(cls):
        return 'sas_attention_feature'

    def _get_dataset(self, mode):
        if mode == 'train':
            return self._get_train_dataset()
        elif mode == 'val':
            return self._get_eval_dataset('val')
        else:
            return self._get_eval_dataset('test')

    def _get_train_dataset(self):
        train_ranges = self.train_targets
        # pdb.set_trace()
        dataset = SasTrainDataset(self.args, self.dataset, self.train_negative_samples, self.rng, train_ranges, self.sas_timestamps)
        return dataset

    def _get_eval_dataset(self, mode):
        positions = self.validation_targets if mode=='val' else self.test_targets
        dataset = SasEvalDataset(self.args, self.dataset, self.test_negative_samples, positions, self.sas_timestamps)
        return dataset

class SasTrainDataset(BertTrainDataset):
    def __init__(self, args, dataset, negative_samples, rng, train_ranges, sas_timestamps):
        super().__init__(args, dataset, negative_samples, rng, train_ranges)
        self.timestamps = sas_timestamps
        self.marank_mode = args.model_code in ['marank']
        self.marank_max_len = args.marank_max_len  # actual max_len if marank_mode=True
        self.output_user = args.dataloader_output_user
        self.item_count = len(dataset['smap'])
        self.item2id = dataset['smap']
        self.attribute_count = len(dataset["attribute2id"])
        # self.id2item = dict([(value, key) for key, value in self.item2id.items()])
        # self.id2attri = dict([(value, key) for key, value in dataset["attribute2id"].items()])
        # self.item2cate = item2cate
        # self.cate2id = cate2id  11149:2098
        # self.item_id2cate_id = dict((self.item2id[key], self.cate2id[value]) for key, value in self.item2cate.items())
        self.item_id2cate_id, self.item_id2brand_id, self.item_id2price_id = dataset['item_id2side_id_tripe'] #item_id to cate_id;
        # pdb.set_trace()
        if self.marank_mode:
            self.user2pos = {user:pos for user, pos in self.train_ranges}
    
    # #设置item_id转化为cate_id的映射字典;
    # def setItemId2CateId(self, item_id2cate_id):
    #     self.item_id2cate_id = item_id2cate_id
    
    def sample_negative_items(self, item_set, item_size):
        import random
        item = random.randint(1, item_size-1) 
        while item in item_set: 
            item = random.randint(1, item_size-1) 
        return item

    def __getitem__(self, index):
        user, offset = self.index2user_and_offsets[index]
        if self.marank_mode:
            # sample offset randomly if marank_mode
            # original offset is generated by max_len,train_window (not marank_max_len) to ensure same amount of computation with other models
            pos = self.user2pos[user]
            offset = self.rng.randint(2, pos)  # offset is exclusive
        max_len = self.max_len if not self.marank_mode else self.marank_max_len
        seq = self.user2dict[user]['items']
        beg = max(0, offset-max_len-1)
        end = offset  # exclude offset (meant to be)
        seq = seq[beg:end]

        tokens = seq[:-1]
        padding_len = max_len - len(tokens)
        if self.marank_mode:
            labels = [seq[-1]]
            neg_samples = self.negative_samples[user]
            negative_labels = [self.rng.choice(neg_samples)]

            tokens = tokens + [tokens[-1]] * padding_len
        else:
            labels = seq[1:]
            neg_samples = self.negative_samples[user]  # a pool of negative items to choose from
            #随机负采样;
            # negative_labels = [self.sample_negative_items(seq, self.item_count) for _ in labels] #将valid item和test item选入到negative items;
            negative_labels = [self.rng.choice(neg_samples) for _ in labels]

            #添加cate_id作为side information;
            pos_cates = [self.item_id2cate_id[value] if value in self.item_id2cate_id else self.attribute_count for value in tokens ]
            pos_cates = [0] * padding_len + pos_cates

            pos_brands = [self.item_id2brand_id[value] if value in self.item_id2brand_id else self.attribute_count +1 for value in tokens]
            pos_brands = [0] * padding_len + pos_brands

            pos_prices = [self.item_id2price_id[value] if value in self.item_id2price_id else self.attribute_count+2 for value in tokens]
            pos_prices = [0] * padding_len + pos_prices

            # pdb.set_trace()
            #添加cate_id作为side information;
            label_cates = [self.item_id2cate_id[value] if value in self.item_id2cate_id else self.attribute_count for value in labels ]
            label_cates = [0] * padding_len + label_cates

            label_brands = [self.item_id2brand_id[value] if value in self.item_id2brand_id else self.attribute_count+1 for value in labels]
            label_brands = [0] * padding_len + label_brands

            label_prices = [self.item_id2price_id[value] if value in self.item_id2price_id else self.attribute_count+2 for value in labels]
            label_prices = [0] * padding_len + label_prices


            #添加cate_id作为side information;
            neg_cates = [self.item_id2cate_id[value] if value in self.item_id2cate_id else self.attribute_count for value in negative_labels]
            neg_cates = [0] * padding_len + neg_cates

            neg_brands = [self.item_id2brand_id[value] if value in self.item_id2brand_id else self.attribute_count+1 for value in negative_labels]
            neg_brands = [0] * padding_len + neg_brands

            neg_prices = [self.item_id2price_id[value] if value in self.item_id2price_id else self.attribute_count+2 for value in negative_labels]
            neg_prices = [0] * padding_len + neg_prices


            tokens = [0] * padding_len + tokens
            labels = [0] * padding_len + labels
            negative_labels = [0] * padding_len + negative_labels

        
        # pdb.set_trace()
        # 数据增强
        d = {
            'tokens': torch.LongTensor(tokens),
            'labels': torch.LongTensor(labels),
            'negative_labels': torch.LongTensor(negative_labels),
            'seq_cates': torch.LongTensor(pos_cates),
            'seq_brands': torch.LongTensor(pos_brands),
            'seq_prices': torch.LongTensor(pos_prices),

            'label_cates': torch.LongTensor(label_cates),
            'label_brands': torch.LongTensor(label_brands),
            'label_prices': torch.LongTensor(label_prices),

            'neg_cates': torch.LongTensor(neg_cates),
            'neg_brands': torch.LongTensor(neg_brands),
            'neg_prices': torch.LongTensor(neg_prices),
        }
        if self.output_timestamps:
            timestamps = self.timestamps[user][beg:end-1]
            timestamps = [0] * padding_len + timestamps
            d['timestamps'] = torch.LongTensor(timestamps)
        if self.output_user:
            d['users'] = torch.LongTensor([user])
        return d


class SasEvalDataset(BertEvalDataset):
    def __init__(self, args, dataset, negative_samples, positions, sas_timestamps):
        super().__init__(args, dataset, negative_samples, positions)
        self.timestamps = sas_timestamps
        self.output_user = args.dataloader_output_user
        self.marank_mode = args.model_code in ['marank']
        self.marank_max_len = args.marank_max_len
        item2id = dataset['smap']
        self.attribute_count = len(dataset["attribute2id"])
        # self.item_id2cate_id = dict((item2id[key], cate2id[value]) for key, value in item2cate.items())
        # self.item_id2cate_id = item_id2cate_id
        self.item_id2cate_id, self.item_id2brand_id, self.item_id2price_id = dataset['item_id2side_id_tripe'] #item_id to cate_id;

    
    def __getitem__(self, index):
        user, pos = self.positions[index]
        seq = self.user2dict[user]['items']
        max_len = self.max_len if not self.marank_mode else self.marank_max_len
        beg = max(0, pos - max_len)
        # end = pos + 1
        # IMPORTANT:
        ## BERT => INLUCDE ANSWER ITEM AND MASK IT
        ## SAS => EXCLUDE ANSWER ITEM
        ## hence end = pos
        end = pos #valid_index: n-2, test_index: n-1
        answer = [seq[pos]]
        seq = seq[beg:end]

        negs = self.negative_samples[user]
        # answer = [seq[-1]]
        candidates = answer + negs
        labels = [1] * len(answer) + [0] * len(negs)

        # IMPORTANT : no [MASK]s for sas
        # so the next line is commented
        # seq[-1] = self.special_tokens.mask
        padding_len = max_len - len(seq)
        if self.marank_mode:
            seq = seq + [seq[-1]] * padding_len
        else:
            #添加cate_id作为side information;
            # cates = [self.item_id2cate_id[value] for value in seq]
            # cates = [0] * padding_len + cates
            cates = [self.item_id2cate_id[value] if value in self.item_id2cate_id else self.attribute_count for value in seq]
            cates = [0] * padding_len + cates

            brands = [self.item_id2brand_id[value] if value in self.item_id2brand_id else self.attribute_count+1 for value in seq]
            brands = [0] * padding_len + brands

            prices = [self.item_id2price_id[value] if value in self.item_id2price_id else self.attribute_count+2 for value in seq]
            prices = [0] * padding_len + prices

            seq = [0] * padding_len + seq

        candidate_cates = [self.item_id2cate_id[value] if value in self.item_id2cate_id else self.attribute_count for value in candidates]
        candidate_brands = [self.item_id2brand_id[value] if value in self.item_id2brand_id else self.attribute_count + 1 for value in candidates]
        candidate_prices = [self.item_id2price_id[value] if value in self.item_id2price_id else self.attribute_count + 2 for value in candidates]

        tokens = torch.LongTensor(seq)
        candidates = torch.LongTensor(candidates)
        labels = torch.LongTensor(labels)
        cates = torch.LongTensor(cates)
        brands = torch.LongTensor(brands)
        prices = torch.LongTensor(prices)

        candidate_cates = torch.LongTensor(candidate_cates)
        candidate_brands = torch.LongTensor(candidate_brands)
        candidate_prices = torch.LongTensor(candidate_prices)

        d = {'tokens':tokens, 'candidates':candidates, 'labels':labels, 'seq_cates': cates, 'seq_brands': brands, 'seq_prices':prices, 
        'candidate_cates': candidate_cates, 'candidate_brands': candidate_brands, 'candidate_prices':candidate_prices}
        if self.output_timestamps:
            timestamps = self.timestamps[user][beg:end]
            timestamps = [0] * padding_len + timestamps
            d['timestamps'] = torch.LongTensor(timestamps)
        if self.output_user:
            d['users'] = torch.LongTensor([user])
        return d