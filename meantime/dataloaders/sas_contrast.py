from .base import AbstractDataloader
from .bert import BertTrainDataset, BertEvalDataset
import pdb
import torch
import copy
import numpy as np


class SasDataloader(AbstractDataloader):
    def __init__(self, args, dataset):
        super().__init__(args, dataset)
        if args.dataloader_output_timestamp:
            self.sas_timestamps = self.calculate_sas_timestamps()
        else:
            self.sas_timestamps = None

    def calculate_sas_timestamps(self):
        sas_timestamps = {}  # user -> timestamps
        for user, dic in self.user2dict.items():
            times = dic['timestamps']
            try:
                time_scale = min(y - x for x, y in zip(times[:-1], times[1:]) if x != y)
            except:
                time_scale = 1
            min_time = min(times)
            sas_timestamps[user] = [round((t-min_time)/time_scale) + 1 for t in times]  # followed authors' original implementation
        return sas_timestamps

    @classmethod
    def code(cls):
        return 'sas_pair'

    def _get_dataset(self, mode):
        if mode == 'train':
            return self._get_train_dataset()
        elif mode == 'val':
            return self._get_eval_dataset('val')
        else:
            return self._get_eval_dataset('test')

    def _get_train_dataset(self):
        train_ranges = self.train_targets
        # pdb.set_trace()
        dataset = SasTrainDataset(self.args, self.dataset, self.train_negative_samples, self.rng, train_ranges, self.sas_timestamps)
        return dataset

    def _get_eval_dataset(self, mode):
        positions = self.validation_targets if mode=='val' else self.test_targets
        dataset = SasEvalDataset(self.args, self.dataset, self.test_negative_samples, positions, self.sas_timestamps)
        return dataset

class SasTrainDataset(BertTrainDataset):
    def __init__(self, args, dataset, negative_samples, rng, train_ranges, sas_timestamps):
        super().__init__(args, dataset, negative_samples, rng, train_ranges)
        self.timestamps = sas_timestamps
        self.marank_mode = args.model_code in ['marank']
        self.marank_max_len = args.marank_max_len  # actual max_len if marank_mode=True
        self.output_user = args.dataloader_output_user
        

        if self.marank_mode:
            self.user2pos = {user:pos for user, pos in self.train_ranges}

    def __getitem__(self, index):
        user, offset = self.index2user_and_offsets[index]
        if self.marank_mode:
            # sample offset randomly if marank_mode
            # original offset is generated by max_len,train_window (not marank_max_len) to ensure same amount of computation with other models
            pos = self.user2pos[user]
            offset = self.rng.randint(2, pos)  # offset is exclusive
        max_len = self.max_len if not self.marank_mode else self.marank_max_len
        seq = self.user2dict[user]['items']
        beg = max(0, offset-max_len-1)
        end = offset  # exclude offset (meant to be)
        seq = seq[beg:end]
        d = {}
        tokens = seq[:-1]
        # pdb.set_trace()
        # (1) 随机crop items, 不保证连续性; 
        # if self.args.argument_type == 'cutoff':
        # if self.args.argument_type == "mask_subseq":
        if "mask_subseq" in self.args.argument_type:
            for key_name in ['tokens_pair1', 'tokens_pair2']:
                # tokens_pair = copy.deepcopy(tokens)
                tokens_pair = copy.deepcopy(seq)
                # s_len = len(seq) - 1 #最后一个不能mask;
                s_len = len(tokens) #最后一个不能mask;
                valid_len = int(self.args.mask_item_rate * s_len)
                import random
                shuffle_index = [index for index in range(s_len)]
                random.shuffle(shuffle_index)
                mask_index = shuffle_index[:valid_len]
                # pdb.set_trace()
                tokens_pair =np.array(tokens_pair)
                tokens_pair[mask_index] = self.special_tokens.mask #用padding替换合理吗? 尝试用MASK替换;
                # pdb.set_trace()
                tokens_pair = tokens_pair.tolist()
                tokens_pair = tokens_pair[-self.max_len:]
                padding_len = self.max_len - len(tokens_pair)
                #开头添加CLS;
                # if padding_len == 0:
                #     tokens_pair[0] = self.special_tokens.cls
                # else:
                #     tokens_pair = [self.special_tokens.cls] + tokens_pair
                #     tokens_pair = [0] * (padding_len-1) + tokens_pair

                #不添加CLS
                tokens_pair = [0] * padding_len + tokens_pair
                d[key_name] = torch.LongTensor(tokens_pair)
                # pdb.set_trace()
        
        # (2) 筛选出部分连续的items; 开头待添加CLS
        # if self.args.argument_type == "cutoff_subseq":
        if  "cutoff_subseq" in self.args.argument_type:
            for key_name in ['tokens_pair1', 'tokens_pair2']:
                # s_len = len(seq) - 1
                s_len = len(tokens)
                valid_len = int(self.args.cutoff_subseq_rate * s_len) + 1
                import random
                start_index = random.randint(0, s_len - valid_len + 1)
                sub_tokens = tokens[start_index:start_index + valid_len]
                # sub_tokens.append(self.special_tokens.cls) #重新添加cls标记位;
                sub_tokens = sub_tokens[-self.max_len:]
                padding_len = self.max_len - len(sub_tokens)
                sub_tokens = [0] * padding_len + sub_tokens
                # d['sub_tokens'] = torch.LongTensor(sub_tokens)
                d[key_name] = torch.LongTensor(sub_tokens)
            # pdb.set_trace()
        # (3) 随机mask一些items, 用[mask] token来代替; MLM中的mask作为输入; 见最后;
        # if self.args.argument_type == "", 
        # (4) items乱序, 分为两个方法: position_ids的乱序和items的乱序(只乱序子序列); 开头待添加CLS
        # if self.args.argument_type == "shuffle_subseq":
        if  "shuffle_subseq" in self.args.argument_type:
            shuffle_subseq = copy.deepcopy(tokens)
            # s_len = len(shuffle_subseq) - 1 #保持最后一个item为cls;
            s_len = len(shuffle_subseq)
            valid_len = int(self.args.shuffle_subseq_rate * s_len)
            import random
            start_index = random.randint(0, s_len - valid_len + 1)
            sub_tokens = shuffle_subseq[start_index:start_index + valid_len]
            random.shuffle(sub_tokens)
            shuffle_subseq[start_index:start_index + valid_len] = sub_tokens #打乱部分items;
            shuffle_subseq = shuffle_subseq[-self.max_len:]
            padding_len = self.max_len - len(shuffle_subseq)
            shuffle_subseq = [0] * padding_len + shuffle_subseq
            # d['shuffle_subseq'] = torch.LongTensor(shuffle_subseq)
            d['tokens_pair2'] = torch.LongTensor(shuffle_subseq)
            # pdb.set_trace()

        # if self.args.argument_type == 'mask_subseq':
        #     tokens_pair = copy.deepcopy(tokens)
        #     # s_len = len(seq) - 1 #最后一个不能mask;
        #     s_len = len(tokens) #最后一个不能mask;
        #     valid_len = int(self.args.mask_subseq_rate * s_len)
        #     import random
        #     shuffle_index = [index for index in range(s_len)]
        #     random.shuffle(shuffle_index)
        #     mask_index = shuffle_index[:valid_len]
        #     # pdb.set_trace()
        #     tokens_pair =np.array(tokens_pair)
        #     tokens_pair[mask_index] = self.special_tokens.mask #用padding替换合理吗? 尝试用MASK替换;
        #     # pdb.set_trace()
        #     tokens_pair = tokens_pair.tolist()
        #     tokens_pair = tokens_pair[-self.max_len:]
        #     padding_len = self.max_len - len(tokens_pair)
        #     #开头添加CLS;
        #     # if padding_len == 0:
        #     #     tokens_pair[0] = self.special_tokens.cls
        #     # else:
        #     #     tokens_pair = [self.special_tokens.cls] + tokens_pair
        #     #     tokens_pair = [0] * (padding_len-1) + tokens_pair

        #     #不添加CLS
        #     tokens_pair = [0] * padding_len + tokens_pair
        #     d['tokens_pair'] = torch.LongTensor(tokens_pair)
        
        padding_len = max_len - len(tokens)
        if self.marank_mode: #marank_mode参数的含义是什么?
            labels = [seq[-1]]
            neg_samples = self.negative_samples[user]
            negative_labels = [self.rng.choice(neg_samples)]

            tokens = tokens + [tokens[-1]] * padding_len
        else:
            labels = seq[1:]
            neg_samples = self.negative_samples[user]  # a pool of negative items to choose from
            negative_labels = [self.rng.choice(neg_samples) for _ in labels]

            tokens = [0] * padding_len + tokens
            labels = [0] * padding_len + labels
            negative_labels = [0] * padding_len + negative_labels
        
        d1 = {
            'tokens': torch.LongTensor(tokens),
            'labels': torch.LongTensor(labels),
            'negative_labels': torch.LongTensor(negative_labels,)
        }

        #更新d1
        d.update(d1)

        if self.output_timestamps:
            timestamps = self.timestamps[user][beg:end-1]
            timestamps = [0] * padding_len + timestamps
            d['timestamps'] = torch.LongTensor(timestamps)
        if self.output_user:
            d['users'] = torch.LongTensor([user])
        return d


class SasEvalDataset(BertEvalDataset):
    def __init__(self, args, dataset, negative_samples, positions, sas_timestamps):
        super().__init__(args, dataset, negative_samples, positions)
        self.timestamps = sas_timestamps
        self.output_user = args.dataloader_output_user
        self.marank_mode = args.model_code in ['marank']
        self.marank_max_len = args.marank_max_len
        self.item_count = len(dataset['smap'])

    def __getitem__(self, index):
        user, pos = self.positions[index]
        seq = self.user2dict[user]['items']
        max_len = self.max_len if not self.marank_mode else self.marank_max_len
        beg = max(0, pos - max_len)
        # end = pos + 1
        # IMPORTANT:
        ## BERT => INLUCDE ANSWER ITEM AND MASK IT
        ## SAS => EXCLUDE ANSWER ITEM
        ## hence end = pos
        end = pos
        answer = [seq[pos]]
        seq = seq[beg:end]

        negs = self.negative_samples[user] #sample负样本;
        #替换为全局数据
        # negs = [index+1 for index in range(self.item_count + 1) if index!=answer[0]]
        # negs = [index+1 for index in range(200) if index!=answer[0]]

        # if len(negs) !=  (self.item_count):
        #     pdb.set_trace()
        # assert len(negs) ==  (self.item_count)
        # pdb.set_trace()
        # answer = [seq[-1]]
        candidates = answer + negs
        labels = [1] * len(answer) + [0] * len(negs)

        # IMPORTANT : no [MASK]s for sas
        # so the next line is commented
        # seq[-1] = self.special_tokens.mask
        padding_len = max_len - len(seq)
        if self.marank_mode:
            seq = seq + [seq[-1]] * padding_len
        else:
            seq = [0] * padding_len + seq

        tokens = torch.LongTensor(seq)
        candidates = torch.LongTensor(candidates)
        labels = torch.LongTensor(labels)
        d = {'tokens':tokens, 'candidates':candidates, 'labels':labels}
        # pdb.set_trace()
        if self.output_timestamps:
            timestamps = self.timestamps[user][beg:end]
            timestamps = [0] * padding_len + timestamps
            d['timestamps'] = torch.LongTensor(timestamps)
        if self.output_user:
            d['users'] = torch.LongTensor([user])
        return d